{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used Language : Python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading MNIST\n",
    "\n",
    "Reference:  \n",
    "https://github.com/Lasagne/Lasagne/blob/master/examples/mnist.py  \n",
    "https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/dataset/mnist.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "import gzip\n",
    "\n",
    "img_size = 784\n",
    "\n",
    "def load_dataset():\n",
    "\n",
    "    def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "        print(\"Downloading %s\" % filename)\n",
    "        urllib.request.urlretrieve(source + filename, filename)\n",
    "\n",
    "    def load_mnist_images(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            download(filename)\n",
    "        \n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "        \n",
    "        data = data.reshape(-1, img_size)\n",
    "        \n",
    "        return data / np.float32(256)\n",
    "\n",
    "    def load_mnist_labels(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            download(filename)\n",
    "        # Read the labels in Yann LeCun's binary format.\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    def _change_one_hot_label(X):\n",
    "        T = np.zeros((X.size, 10))\n",
    "        for idx, row in enumerate(T):\n",
    "            row[X[idx]] = 1\n",
    "        \n",
    "        return T\n",
    "\n",
    "    \n",
    "    X_train = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "    y_train = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "    X_test = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "    y_test = load_mnist_labels('t10k-labels-idx1-ubyte.gz')\n",
    "    \n",
    "    y_train = _change_one_hot_label(y_train)\n",
    "    y_test =  _change_one_hot_label(y_test)\n",
    "\n",
    "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz\n",
      "Downloading train-labels-idx1-ubyte.gz\n",
      "Downloading t10k-images-idx3-ubyte.gz\n",
      "Downloading t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing 3 layer Neural Network  \n",
    "Reference :   \n",
    "https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/ch04/two_layer_net.py  \n",
    "https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/ch04/train_neuralnet.py  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# クラス内で使用する関数の定義\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_diff(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)\n",
    "\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "    \n",
    "    x = x - np.max(x) \n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "    \n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:   \n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size\n",
    "\n",
    "class Three_Layer_NN:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_1_size, hidden_2_size, output_size, std=0.01):\n",
    "        \n",
    "        self.params = {}\n",
    "        self.params['W1'] = std * np.random.randn(input_size, hidden_1_size)\n",
    "        self.params['b1'] = np.zeros(hidden_1_size)\n",
    "        self.params['W2'] = std * np.random.randn(hidden_1_size, hidden_2_size)\n",
    "        self.params['b2'] = np.zeros(hidden_2_size)\n",
    "        self.params['W3'] = std * np.random.randn(hidden_2_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "    \n",
    "    \n",
    "    def loss(self, X, t=None):\n",
    "        W1, b1 = self.params['W1'], self.params['b1']\n",
    "        W2, b2 = self.params['W2'], self.params['b2']\n",
    "        W3, b3 = self.params['W3'], self.params['b3']\n",
    "        \n",
    "        \n",
    "        # forward\n",
    "        U1 = np.dot(X, W1) + b1    \n",
    "        Z1 = sigmoid(U1)           \n",
    "        U2 = np.dot(Z1, W2) + b2\n",
    "        Z2 = sigmoid(U2)\n",
    "        U3 = np.dot(Z2, W3) + b3\n",
    "        y = softmax(U3)     \n",
    "                \n",
    "        if t is None:\n",
    "            return y\n",
    "        \n",
    "        # loss function\n",
    "        loss = cross_entropy_error(y, t)    \n",
    "        \n",
    "        # back propagation\n",
    "        grads = {}\n",
    "        batch_num = X.shape[0]\n",
    "        \n",
    "        delta_3 = (y - t) / batch_num        \n",
    "        grads['W3'] = np.dot(Z2.T, delta_3)\n",
    "        grads['b3'] = np.sum(delta_3, axis=0)\n",
    "        \n",
    "        delta_2 = (np.dot(delta_3, W3.T)) * sigmoid_diff(U2)\n",
    "        grads['W2'] = np.dot(Z1.T, delta_2)\n",
    "        grads['b2'] = np.sum(delta_2, axis=0)\n",
    "        \n",
    "        delta_1 = (np.dot(delta_2, W2.T)) * sigmoid_diff(U1)\n",
    "        grads['W1'] = np.dot(X.T, delta_1)\n",
    "        grads['b1'] = np.sum(delta_1, axis=0)\n",
    "        \n",
    "        return loss, grads\n",
    "    \n",
    "    \n",
    "    def train(self, X, t, X_val, y_val, learning_rate=0.1, num_iters=10000, batch_size=100):\n",
    "        \n",
    "        iter_per_epoch = max(X.shape[0] / batch_size, 1)\n",
    "        \n",
    "        for i in range(num_iters):\n",
    "            batch = np.random.choice(X.shape[0], batch_size)\n",
    "            X_batch = X[batch]\n",
    "            t_batch = t[batch]\n",
    "            \n",
    "            loss, grads = self.loss(X_batch, t_batch)\n",
    "            \n",
    "            for key in ('W1', 'b1', 'W2', 'b2', 'W3', 'b3'):\n",
    "                self.params[key] -= learning_rate * grads[key] \n",
    "            \n",
    "            if i % iter_per_epoch == 0:\n",
    "                train_acc = self.accuracy(X, t)\n",
    "                val_acc = self.accuracy(X_val, y_val)\n",
    "                print(\"train acc, val acc | \" + str(train_acc) + \", \" + str(val_acc))\n",
    "                \n",
    "        print(\"Finish!\")\n",
    "            \n",
    "    \n",
    "    def predict(self, X):    \n",
    "        return self.loss(X)\n",
    "    \n",
    "    def accuracy(self, X, t):\n",
    "        y = self.predict(X)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(X.shape[0])\n",
    "        return accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding the data and Checking the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, val acc | 0.09864, 0.0991\n",
      "train acc, val acc | 0.11356, 0.1064\n",
      "train acc, val acc | 0.10202, 0.103\n",
      "train acc, val acc | 0.09976, 0.0961\n",
      "train acc, val acc | 0.11356, 0.1064\n",
      "train acc, val acc | 0.20476, 0.1989\n",
      "train acc, val acc | 0.31916, 0.3199\n",
      "train acc, val acc | 0.48556, 0.4974\n",
      "train acc, val acc | 0.62078, 0.6502\n",
      "train acc, val acc | 0.73884, 0.7664\n",
      "train acc, val acc | 0.78704, 0.8054\n",
      "train acc, val acc | 0.81898, 0.8339\n",
      "train acc, val acc | 0.84254, 0.8523\n",
      "train acc, val acc | 0.85814, 0.8669\n",
      "train acc, val acc | 0.86812, 0.8756\n",
      "train acc, val acc | 0.8738, 0.8787\n",
      "train acc, val acc | 0.88472, 0.8903\n",
      "train acc, val acc | 0.89238, 0.8968\n",
      "train acc, val acc | 0.89856, 0.904\n",
      "train acc, val acc | 0.90402, 0.9073\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "# Learnig rate : 0.1\n",
    "# Iteration : 10000\n",
    "# Batch size : 100\n",
    "network = Three_Layer_NN(input_size=784, hidden_1_size=255, hidden_2_size=75, \n",
    "                         output_size=10, std=0.01)\n",
    "\n",
    "network.train(X_train, y_train, X_val, y_val, learning_rate=0.1, num_iters=10000, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90869999999999995"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.accuracy(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, val acc | 0.09684, 0.1009\n",
      "train acc, val acc | 0.39732, 0.405\n",
      "train acc, val acc | 0.82864, 0.8452\n",
      "train acc, val acc | 0.91614, 0.9182\n",
      "train acc, val acc | 0.9413, 0.9464\n",
      "train acc, val acc | 0.95174, 0.9565\n",
      "train acc, val acc | 0.96304, 0.9614\n",
      "train acc, val acc | 0.9688, 0.9652\n",
      "train acc, val acc | 0.96764, 0.9642\n",
      "train acc, val acc | 0.97062, 0.9639\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "# Learnig rate : 1.1\n",
    "# Iteration : 5000\n",
    "# Batch size : 100\n",
    "network = Three_Layer_NN(input_size=784, hidden_1_size=255, hidden_2_size=75, \n",
    "                         output_size=10, std=0.01)\n",
    "\n",
    "network.train(X_train, y_train, X_val, y_val, learning_rate=1.1, num_iters=5000, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96909999999999996"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.accuracy(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
